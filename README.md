# openMaze_XAI

This repository is dedicated to exploring eXplainable AI (XAI) techniques for Large Language Models (LLMs). It contains two main projects: an attention visualization tool and a backend for LLM-based interpretability.

## Projects

### [Attention Visualization](./Attention%20Visualization/)

A full-stack application to run LLMs locally and visualize their attention patterns. This tool provides an interactive way to explore the internal workings of language models.

- **Backend**: Python, Flask, Transformers
- **Frontend**: HTML, CSS, JavaScript

### [LLM-Based Interpretability](./LLM-Based%20Interpretability/)

This project contains backend components for interpreting the outputs of LLMs. It includes tools for data processing with GPT-4 and for interacting with LLMs using Ollama.

## Overview

The two projects in this repository are designed to work together. The `Attention Visualization` tool can be used to generate attention data from an LLM, and the `LLM-Based Interpretability` components can be used to analyze and interpret this data.

Please refer to the `README.md` files in each subdirectory for more detailed information and setup instructions.
